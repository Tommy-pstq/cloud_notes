2024-11-13 17:02

Alizée Lopez-Persem, Mehdi Khamassi 

Tags:

# Décision et action - NscCog - 4


## Introduction 

Price de décision = processus cognitif permettant la sélection d'un option/action parmi ensemble d'alternatives résultant un choix: comportement observable.

En neurosciences cognitives, l'étude de la [[prise de décision]] est centrée sur:
- Les décisions perceptives 
- Les décisions fondées sur la récompense (économique)
## II Différents types de décisions

Ambiguïté perceptive : deux rond au dessus d'un trait = visage -> danger ? 
	-> Décider de ce que l'on voit = [[décision perceptive]]. 

### II - 1 Les [[décision économique|décisions économiques]]

- Implique la comparaison de différents attributs pour déduire quelle est la meilleure option.
	- Ex : préférences de goûts / apport calories / prix / distance pour le choix d'un repas.
	- Utilisation d'une [[valeur subjective]] par le cerveau pour comparer les différents critères entre eux. 
Décision économiques = comparaison de valeurs:
- Monétaire 
- Energétique (nourriture)
- [[social]] (acquiescement des pairs )

### II - 2  Les décisions perceptives

Concerne principalement les signaux sensoriels ambiguës.
1. Traités par les cortex sensoriels
2. Traités par les cortex associatifs (Ex: [[cortex pariétal]] : intégration des différentes informations sensorielles)
3. Décision perceptive : Choix d'une hypothèse sur l'état estimé du monde. 

Ex : Cube de Necker. 

Situations écologiques: la plupart des décisions perceptives sont traitées de manière implicite & automatique.

## Les décisions : de la valeur à l'action.
Focus sur les décisions économiques 

### III - 1 Le concept de la valeur subjective
#### III - 1 - 1 En philosophie

valeur subjective = quantité de plaisir. 

Eviter la douleur / rechercher du plaisir = apparition de [[désir]].

Aspect unitaire du plaisir, central pour tenter de l'expliquer. Beaucoup de débats à ce propos. Différent degré de [[conscience]] : J'aime quelque chose // Je suis conscience que j'aime quelque chose. 

#### III - 1 - 2 En économie

Etude de la prise de décision: l'humain devrait être rationnel, ses décisions devraient donc servir à optimiser une notion d'**utilité**. 

Utilité = valeur subjective dépendant du contexte et de l'individu, non une valeur absolue (Daniel Bernoulli). 
	-> Distinction entre valeur objective/absolue (prix) et sa valeur subjective (utilité).
	 
#### III - 1 - 3 Apprentissage par renforcement

1905 : **Loi de l'effet**: les réponses comportementales qui produisent un effet positif dans une situation particulière deviennent plus susceptibles de se reproduire (acquisition d'une valeur subjective plus grande), tandis que les réponses qui produisent un effet négatif sont moins susceptibles de se répéter (diminution de la valeur subjective).
	-> La valeur subjective n'est pas fixe.

1927: **conditionnement pavlovien**. Les philosophes & économiste supposaient les plaisirs anticipés & vécus comme un seul concept unique: pas vraiment.

1972: **Formalisation** du conditionnement pavlovien: l'apprentissage vient de la différence entre ce qui est attendu et ce qui est vécu.
	-> Notion d'erreur de prédiction.

#### III - 1 - 4 Mesurer les valeurs subjectives en neurosciences cognitives.

- 4 grand types de mesures des valeurs subjectives.
	1. Tâches de notation: évaluation via une valeur sur une échelle d'à quel point il serait agréable d'obtenir un élément.
	2. Notion de coût: propension à payer, indication des participants combien ils seraient prêts à payer pour obtenir un objet présenter.
	3. Similaire au 2) : Quel quantité d'effort les participants sont prêts à fournir pour obtenir une récompense.
	4. Tâches de choix binaires. Mesure ordinale et non cardinale: on mesure quel est le rang de la valeur subjective des items entre eux. 
			- Distance de valeur entre deux éléments: 
				1. Vitesse de choix
				2. Fréquence de choix de A vs B

### III - 2 Valeurs et choix
#### Les étapes d'un choix
 Théorie unificatrice de la prise de décision fondée sur la valeur : 2008.
1. **Représentation**. De l'environnement, des états internes & des options disponibles.
2. **Évaluation**. Attribution d'une valeur subjective à chaque action, en fonction de la représentation. Valeur d'action $\neq$ valeur de récompense : différents types de valeur
3. **Sélection de l'action**. = prise de décision, en se basant sur les valeurs attribuées lors de l'étape d'évaluation, la meilleure est sélectionnée. Plusieurs systèmes d'évaluation peuvent entrer en conflit à ce stade. 
4. **Evaluation des conséquences**. 
5. **Apprentissage**. Mise à jour de: 
	1. La représentation des actions & états.
	2. La valeur de l'action via l'erreur de prédiction.
	3. Les processus de sélection des actions. 

#### Plusieurs systèmes d'évaluation. 

- **Système Pavlovien**
	- Attribue des valeurs aux signaux environnementaux par expositions répétitives. 
	- Ne porte que sur des stimuli externes prédictifs de récompenses, même lorsque l'agent est passif. 
	- Peut influencer les valeurs attribués aux stimuli lors de processus de décision via les autres systèmes (habituel & orienté vers un but): biaise la décision. (Pavlov-To-Instrumental Transfert)

- **Système habituel**
	- Basé sur les actions. Tous types de comportements appris par des entrainements répétés. 
	- Attribution d'une valeur à une option par l'association d'un [[stimulus]] à une réponse ([[S-R]]) 
	- Apprentissage procédural, implicite & automatique. 
		- Situations familières, par fainéantise ou économie de temps: les décisions peuvent émanées du système habituel: plus rapide & évite les phases de délibérations. 
		- -> Plus sensible aux biais cognitifs. 
	- Nécessite plusieurs répétitions ne donnant pas de réaction positives pour que la valeur subjective diminue 

- **Système dirigé vers les buts** 
	- Attribue des valeurs aux actions. 
	- Association entre actions  & résultats escomptés (contingence entre l'action et sa conséquence)
	- Déduction de la valeur de l'action par l'estimation mentale de ses conséquence futures.
		- Phase de délibération lors du processus d'estimation (inférence).
			- Lent.
	- Permet une réaction flexible (à l'environnement ou à un état interne comme la satiété)


Ex sys. habituel vs dirigé vers les buts: Dans une partie d'échecs, un coup peut être jouer à partir d'une intuition de ce qui semble être le meilleur coup (=système habituel entrainé pour un joueur régulier) ou via un calcul d'un enchainement de coups possible (=système orienté vers les buts)

### III - 3 Expliquer les choix à partir des valeurs subjectives

Décision dirigé vers un but: utilisation de valeurs subjectives. 
	-> Argmax() des valeurs pour la prise de décision ?
		-> Les observations sont souvent contradictoires avec cette idée. 

-> Deux types de modèles:
	1. Statiques : proposent des mécanisme pour expliquer les choix. 
	2. Dynamiques : Explique les choix & le temps de prise de décision. 
		- initialement pensés pour évaluer les décisions perceptuelles.

#### Modèles statique de la prise de décision 

- **Modèles descriptifs**: Utilisation de méthodes probabilistes comme l'ajustement d'une fonction *softmax*. 
	- Permet d'expliquer l'augmentation du nombre d'erreurs quand deux choix sont proches.
	- Modèles les plus simples: 2 paramètres.
		- Constante de biais. 
		- Température inverse: représente le bruit entre les choix. 
	- N'apporte aucunes explications sur les mécanisme de prise de décisions.
		- -> Développement de modèles plus mécanistiques (explicatifs en matière de mécanisme).

- **Théorie de la détection du signal**
	- Quatre types de réponse possible lorsque l'on doit détecter la présence d'un stimulus.
		1. Détection correcte (True positive)
		2. Erreur d'omission (False negative)
		3. Fausse alarme (False positive)
		4. Rejet correct (True negative)
	- Permettent le calcule de métriques:
		- Sensibilité ($d'$) au stimulus - paramètre perceptif
		- Biais de réponse ($\beta$) qui indique si le sujet est conservateur (évite les fausses alarmes) ou libéral (évite les omission)
		![[Pasted image 20241118171405.png|450]]
Modèle très utilisé en [[psychophysique]]. 
Mais: 
Si valeur subjective = distribution interne de probabilité
	-> Deux valeurs proches = peu discriminables ($d'$ petit, % d'erreur augmente)
		-> Un seul type d'erreur : ne pas choisir celle avec la valeur la plus élevée.
			-> Le biais de décision s'exprimerait (ou non) sur l'une ou l'autre option, selon le contexte et les a priori. 

- Théorie de la détection du signal (TDS) = base de la prise de [[décision perceptive]]. 
- Développée pour expliquer des décision liées à la **détection** de stimuli bruités:
	- Pas de prise en compte de la dynamique du processus de décision (plus un choix est difficile, plus la prise de décision est lente).
	- -> A été étendue à des formes dynamiques compatibles avec la prise de décisions fondée sur la valeur.

#### Modèles dynamiques de prise de décision. 

- TDS étendue aux modèles dynamiques: à chaque instant $t$ du processus de décision général, si le stimulus est présent, une information est ajoutée à la précédente.
- Modèles d'[[échantillonnage]] séquentiel développés sur cette idée d'accumulation d'évidence en faveur de l'une ou l'autre des options.
	- L'information s'accumule sur une option jusqu'à ce qu'un seuil soit atteint. 
		- Ce seuil est atteint au bout d'un temps $t_r$ = temps de réaction, le critère de décision atteint à $t=t_r$  définit le choix qui est fait.
		- Processus stochastique: information bruitée. donc $t_r$ variable. 
	- Temps de non décision pouvant être introduit avant le début de l'accumulation pour la prise en compte de processus non liés à la décision
		- identification du stimulus
		- accès à des informations en [[mémoire]] 
	- Pression temporelle -> Diminution du seuil de décision
	- Un a priori sur l'évidence (croyances) -> modifie la valeur de départ

## Les bases neurales de la prise de décision

### IV - 1 Représentation des valeurs de récompense dans le cerveau 

#### Le [[cortex orbito-frontal]] (OFC)

- Sous partie du [[cortex préfrontal]].
- Etudes d'auto-stimulation de l'OFC chez les singes:
	- Auto-stim augmente lorsque le singe a faim que lorsqu'il est rassasié 
	- Valeur **subjective** de la nourriture plus élevée lorsque l'on a faim.
- Lésions OFC:
	- Comportements de persévération
	- Augmentation des comportements d'approche non alimentaire chez les singes.
		- Quand ils sont mis face à un objet sans aucun valeur particulière, ils le portent à la bouche, comme s'il avait un intérêt alimentaire. 
			- Etudes suivantes ont montrées que que c'est l'association entre le stimulus et la récompense qui était altérée: le système dirigé vers les buts ne peut plus estimer quel stimulus a des chances d'être suivi de récompense.

-> OFC = région importante pour l'attribution d'une valeur à un stimulus ou un objet. 

#### La [[dopamine]]

OFC permet de mémoriser des associations stim-recompense.
	-> De quelle partie du cerveau provient l'info sur la valeur de la récompense ?
	
Réseau de fibres venant de tronc cérébral (medial forebrain bundle ([[MFB]])) transmet de la dopamine jusque dans l'OFC.

**Signale** & **quantifie** la récompense, ainsi que sa **probabilité d'occurrence**, ainsi que sa **pertinence de mémorisation $^*$ ***.
- $*$ Si une association stim-recompense est déjà bien connue : pas besoin de la renforcer d'avantage au niveau neural. 
	- -> Il n'est pertinent d'envoyer des signaux de renforcement au [[cortex préfrontal]] uniquement lors de l'obtention d'une nouvelle récompense. 
	- Le niveau de surprise lié à un récompense est à prendre en compte dans tout signal de renforcement. 

Les neurones dopaminergiques (mésencéphale - [[VTA]] ou [[substance noire]]) répondent spécifiquement selon un principe d'**erreur de prédiction de la récompense**:
	- Réception de récompense inattendue: augmentation du taux de décharge. 
		- Erreur de prédiction positive
	- Si un stimulus est prédicteur de récompense: augmentation du taux de décharge **lors du stimulus** mais pas lors de l'obtention de la récompense. 
	- Signal mais pas de récompense: diminution du taux de décharge.
		- Erreur de prédiction négative

#### Le [[striatum]] 



## Refs
